**How to model hit or loss models**

Hit or loss models can be modeled by discrete processes such as Bernoulli or Binomial processes, in which a variable testify whther the process has reached his goal (1) or hat missed it (0). Digital Marketing often has processes that reminds this binary possibility, such as the marketing study for an effective campaign.
In the following, I took inspiration from a four parts article on how data science and reinforcement learning can be effectively, which tackle a concrete marketing analytics problem. The original article has been written by Roopam Upadhyay in his blog YOU CANalytics (complete link to the first part: http://ucanalytics.com/blogs/reinforcement-learning-and-artificial-intelligence-digital-marketing-case-study-example-part-1/).
There a nice review of A/B testing and its integration with Bayesian models is presented.


**Conjugate Priors**

If the posterior distributions *p(θ|x)* are in the same family as the prior probability distribution *p(θ)*, the prior and 
posterior are then called conjugate distributions, and the prior is called a conjugate prior for the likelihood function. 
It is indeed the case for Bernoulli and Beta distribution, the first describing a count process. Consider a random variable 
which consists of the number of successes in *n* Bernoulli trials with unknown probability of success *q* in [0,1].  the usual conjugate prior is the beta distribution with parameters *(alpha,beta)*.
One can check that a Beta distribution can in fact be approximated with a Gaussian for some opportune choice of the parameters

We would need the following function in order to infer an approximated Beta Distribution with parameters (alpha,beta) starting from a Gaussian Distribution with parameters (mean,variance) 

```
Beta_Parameters <- function(mean, variance) {
  alpha <- ((1 - mean) / variance - 1 / mean) * mean ^ 2
  beta <- alpha * (1 / mean - 1)
  return(Beta_Parameters = list(alpha = alpha, beta = beta))
}
```

**Raw A/B Testing**
We say that a result of a test is statistically significant if it is unlikely to have occurred by chance alone in a given setting.
We decide on two rival hypotheses – the Null Hypothesis and the Alternative Hypothesis.
The Null Hypothesis is the assumption that there is no relationship between the values. Usually, we set it to the exact opposite of what we would like to see. When expecting a higher conversion rate on the new landing page, use a Null Hypothesis that the mean conversion rates are equal.
The Alternative Hypothesis is what we must assume once the Null Hypothesis is rejected. There are many types of Alternative Hypotheses, but in most A/B tests it is usually enough to know the two values are different. In these cases we will use a Two-tailed alternative hypothesis. A One-tailed alternative allows us to specify the direction of inequality.
The result of the test is either to reject the Null Hypothesis while accepting the Alternative Hypothesis or conclude that there is not enough evidence to reject the Null Hypothesis. Note that we have no way of confirming the Null. If you fail to reject the hypothesis that there is no difference in Conversion Rates between two ads, you should not conclude that the two conversion rates are equal. Maybe your sample was too small to detect the difference?
We select a Significance Level – the probability of detecting an effect that is not there. Stat-gurus call it the probability of a Type I Error or the probability of a False-Positive detection (read more on types of error here). Usually, we select a number that is less or equal than 5% (hence we have a 5% chance of making a mistake when rejecting the Null).
We should also select the Power of Test, which is the probability of finding an effect that exist. This is also called the probability of a True-Positive. Commonly chosen values are 80% or 90%.
We calculate the p-value from the Test Statistic. It is the probability that the observed result is due to chance assuming the Null Hypothesis holds. P-value is what you usually see reported instead of the Test Statistic because it is easy to interpret.
To reject the Null Hypothesis we need a p-value that is lower than the selected Significance Level.


**Hypothesis Testing**
Usually in a marketing analysis n there are running candidates (i.e. possible campaigns) that are competing. 
Let us suppose that three candidate distribution follow some Beta distribution profile,representing the chance of having a valid campaign. We would like to discriminate which one is better than the other using some statistics. An easy way is to draw samplex 
One can use the foudn distribution to check whether in cases A,B and C there is some statistical significance, first generating a high number of points (10^6) from the two distributions
```
a_simulation=rbeta(10^6,a$alpha,a$beta)
b_simulation=rbeta(10^6,b$alpha,b$beta)
c_simulation=rbeta(10^6,c$alpha,c$beta)
```
then checking in how many cases points from A are greater from points from B (and all other combinations) by using the a pointwise comparison of the sampled points
```
mean(b_simulation>a_simulation)
mean(c_simulation>b_simulation)
mean(c_simulation>a_simulation)
```
It is evident from here




**Role and advantage of Reinforcement Learning**
Nowadays, software agents ought to take actions in one environment in order to maximise some obtained reward by iteratively interacting with the outer environment. By this back and fourth iteration, to an action it follows the delivery of some reward.
The appeal of this dynamical learning in that a strategy results, for free, as the set of actions which lead to the maximum reward obtainable. This in turns changing the way systems to be no longer rule-based but automated in a way they can _adapt_ to the actual needs of a specific customer, i.e. tailoring the strategy to the need of a customer. The customer is indeed becoming the main character, while the focus on products themselves is getting less and less important.
In addition to the link between [Thompson Sampling](http://en.wikipedia.org/wiki/Thompson_sampling) and [Reinforcement Learning](https://en.wikipedia.org/wiki/Reinforcement_learning), I met the other paper [Cross Channel Optimized Marketing by Reinforcement Learning](http://www.research.ibm.com/people/n/nabe/kdd04AVAS.pdf) which again addresses an online email campaign this time caring about life time of customers in terms of a Markov Decision Process.
Recall that Markov decision processes (MDPs) provide a mathematical framework for modeling decision making in situations where outcomes are partly random and partly under the control of a decision maker.




